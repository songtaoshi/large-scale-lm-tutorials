{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Large-scale language modeling tutorials with PyTorch\n",
    "\n",
    "<br>\n",
    "\n",
    "![](../images/megatron_3d.png)\n",
    "\n",
    "<br>\n",
    "\n",
    "안녕하세요. 저는 TUNiB에서 머신러닝 엔지니어로 근무 중인 고현웅입니다. 이 발표는 대규모 언어모델 개발에 필요한 여러가지 기술들을 소개드리기 위해 마련하였으며 기본적으로 PyTorch와 Transformer 언어모델에 대한 지식이 있다고 가정하고 만든 자료입니다. 매 세션이 끝나고 Q&A 시간이 있으니 듣는 도중 모르시는 내용은 정리를 해두셨다가 질문해주시면 감사하겠습니다. :)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Index\n",
    "01. Introduction\n",
    "  - Index\n",
    "  - Environments\n",
    "  - Postscript\n",
    "02. Motivation\n",
    "  - Why Large Scale?\n",
    "  - Large-scale의 시대에 우리는 무엇을 준비해야 할까?\n",
    "03. Distributed Programming\n",
    "  - Multi-processing with PyTorch\n",
    "  - Distributed Programming with PyTorch\n",
    "04. Overview of Parallelism\n",
    "  - Parallelism\n",
    "  - Data Parallelism\n",
    "  - Model Parallelism\n",
    "  - Multi-dimensional Parallelism\n",
    "05. Data Parallelism\n",
    "  - `torch.nn.DataParallel`\n",
    "  - `torch.nn.DataParallel`의 문제점\n",
    "  - `torch.nn.parallel.DistributedDataParallel`\n",
    "06. Pipeline Model Parallelism\n",
    "  - Inter-layer model parallelism\n",
    "  - GPipe\n",
    "  - 1F1B Pipelining\n",
    "  - Variation of 1F1B Pipelining\n",
    "  - Intereaved Scheduling\n",
    "07. Tensor Model Parallelism\n",
    "  - Intra-layer model parallelism\n",
    "  - Megatron-LM\n",
    "  - Parallelformers\n",
    "08. Zero Redundancy Optimization\n",
    "09. Multi-dimensional Parallelism\n",
    "10. Additional Techniques  \n",
    "11. Oslo (beta) - TUNiB이 개발중인 프레임워크"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Envrionments\n",
    "### Local Environments\n",
    "- Linux Ubuntu 18.04 LTS\n",
    "- 4 * A100 GPU\n",
    "- Python 3.7\n",
    "- pytorch==1.9.0+cu111\n",
    "\n",
    "### Docker Environments\n",
    "- `pytorch/pytorch:1.9.0-cuda11.1-cudnn8-runtime`\n",
    "- `--shm-size`를 키우거나 `--ipc=host` 옵션을 설정해주세요."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Postscript\n",
    "- 목차의 대분류는 '세션', 소분류는 '챕터'라고 명명하였습니다. 용어에 혼동이 없으시길 바랍니다. <br>\n",
    "- 모든 강의자료 및 노트북 파일은 https://github.com/hyunwoongko/large-scale-transformers 이곳에 공개되어 있습니다. <br>\n",
    "- 본 발표는 실습위주의 발표입니다. 이론 위주의 발표는 https://www.youtube.com/watch?v=w4a-ARCEiqU 이곳을 참고하세요."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}