{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Large Scale Transformers with PyTorch\n",
    "\n",
    "안녕하세요. 저는 TUNiB에서 머신러닝 엔지니어로 근무 중인 고현웅입니다. 이 발표는 대규모 언어모델 개발에 필요한 여러가지 기술들을 소개드리기 위해 마련하였으며 기본적으로 PyTorch와 Transformer 언어모델에 대한 지식이 있다고 가정하고 만든 자료입니다. 매 세션이 끝나고 Q&A 시간이 있으니 듣는 도중 모르시는 내용은 정리를 해두셨다가 질문해주시면 감사하겠습니다. :)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Index\n",
    "- Fundamentals\n",
    "- Distributed Operations\n",
    "  - Message Passing\n",
    "  - `torch.distributed`\n",
    "- Data Parallelism\n",
    "  - `nn.DataParallel`\n",
    "  - Distributed Process\n",
    "  - `nn.parallel.DistributedDataParallel`\n",
    "- Tensor Model Parallelism\n",
    "  - Megatron-LM\n",
    "  - Parallelformers\n",
    "- Pipeline Model Parallelism\n",
    "  - PyTorch PipelineModule\n",
    "  - DeepSpeed PiperineModule\n",
    "- ZeRO Data Parallelism\n",
    "  - Mixed Precision\n",
    "  - ZeRO stage 1, 2, 3\n",
    "  - ZeRO offload & infinity\n",
    "  - DeepSpeed\n",
    "- Multi-dimensional Parallelism\n",
    "  - MPU (model parallel unit)\n",
    "  - Megatron family\n",
    "- Additional Techniques  \n",
    "  - Kernel Fusion\n",
    "  - Activation Checkpointing\n",
    "  - Sparse Attention\n",
    "- Oslo (beta) - TUNiB이 개발중인 프레임워크\n",
    "  - Background\n",
    "  - Usage\n",
    "  - Future Plan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Postscript\n",
    "- 모든 강의자료 및 노트북 파일은 https://github.com/hyunwoongko/large-scale-transformers 이곳에 공개되어 있습니다. <br>\n",
    "- 본 발표는 실습위주의 발표입니다. 이론 위주의 발표는 https://www.youtube.com/watch?v=w4a-ARCEiqU 이곳을 참고하세요."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
