{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Parallelism\n",
    "\n",
    "- 이번 세션에는 데이터 병렬화 기법에 대해 알아보겠습니다.\n",
    "\n",
    "## 1. `torch.nn.DataParallel`\n",
    "- Data Parallelism은 `all-reduce` 연산을 활용하기 전과 후로 나뉩니다.\n",
    "- 가장 먼저 우리에게 친숙한 `torch.nn.DataParallel`의 동작 방식에 대해 알아봅시다.\n",
    "- `torch.nn.DataParallel`은 single-node & multi-GPU에서 동작하는 multi-thread 모듈입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Forward Pass\n",
    "\n",
    "1. 입력된 mini-batch를 **Scatter**하여 각 디바이스로 전송.\n",
    "2. GPU-1에 올라와 있는 모델의 파라미터를 GPU-2,3,4로 **Broadcast**.\n",
    "3. 각 디바이스로 복제된 모델로 Forward하여 출력값을 구함.\n",
    "4. 구해진 출력값들을 **Gather**하여 GPU-1에 모음.\n",
    "\n",
    "![](../images/dp_forward.png)\n",
    "\n",
    "<br>\n",
    "\n",
    "- 코드로 나타내면 아래와 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_parallel(module, input, device_ids, output_device):\n",
    "    inputs = nn.parallel.scatter(input, device_ids)\n",
    "    # 입력 데이터를 device_ids들에 Scatter함\n",
    "\n",
    "    replicas = nn.parallel.replicate(module, device_ids)\n",
    "    # 모델을 device_ids들에 복제함.\n",
    "   \n",
    "    outputs = nn.parallel.parallel_apply(replicas, inputs)\n",
    "    # 각 device에 복제된 모델이 각 device의 데이터를 Forward함.\n",
    "\n",
    "    return nn.parallel.gather(outputs, output_device)\n",
    "    # 모델의 출력값을 output_device(하나의 device)로 모음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Backward Pass\n",
    "\n",
    "1. GPU-1에 모여있는 출력값과 라벨을 이용하여 GPU-1에서 모든 Loss를 계산.\n",
    "2. 계산된 각각의 Loss를 각 디바이스에 **Scatter**함.\n",
    "3. 전달받은 Loss를 이용해서 각 디바이스에서 Backward를 수행.\n",
    "4. 계산된 모든 Gradient를 GPU-1로 **Reduce**하여 GPU-1의 모델을 업데이트.\n",
    "\n",
    "![](../images/dp_backward.png)\n",
    "\n",
    "<br>\n",
    "\n",
    "### 혹시나 모르시는 분들을 위해...\n",
    "- `loss.backward()` 기울기를 미분해서 Gradient를 계산\n",
    "- `optimizer.step()` 계산된 Gradient를 이용해서 파라미터를 업데이트\n",
    "- Computation cost는 `backward()` > `step()`.\n",
    "\n",
    "![](../images/dp_backward_loss.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import BertForSequenceClassification, BertTokenizer\n",
    "from datasets import load_dataset\n",
    "\n",
    "# 1. create dataset\n",
    "datasets = load_dataset(\"multi_nli\").data[\"train\"]\n",
    "datasets = [\n",
    "    {\n",
    "        \"premise\": str(p),\n",
    "        \"hypothesis\": str(h),\n",
    "        \"label\": l.as_py(),\n",
    "    }\n",
    "    for p, h, l in zip(datasets[2], datasets[5], datasets[9])\n",
    "]\n",
    "data_loader = DataLoader(datasets, batch_size=32, num_workers=4)\n",
    "\n",
    "# 2. create model and tokenizer\n",
    "model_name = \"bert-base-cased\"\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertForSequenceClassification.from_pretrained(model_name, num_labels=3).cuda()\n",
    "\n",
    "# 3. make data parallel module\n",
    "# device_ids: 사용할 디바이스 리스트 / output_device: 출력값을 모을 디바이스\n",
    "model = nn.DataParallel(model, device_ids=[0, 1, 2, 3], output_device=0)\n",
    "\n",
    "# 4. create optimizer\n",
    "optimizer = Adam(model.parameters(), lr=3e-5)\n",
    "\n",
    "# 5. start training\n",
    "for i, data in enumerate(data_loader):\n",
    "    optimizer.zero_grad()\n",
    "    tokens = tokenizer(\n",
    "        data[\"premise\"],\n",
    "        data[\"hypothesis\"],\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "\n",
    "    loss = model(\n",
    "        input_ids=tokens.input_ids.cuda(),\n",
    "        attention_mask=tokens.attention_mask.cuda(),\n",
    "        labels=data[\"label\"].cuda(),\n",
    "    ).loss.sum()\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if i % 10 == 0:\n",
    "        print(f\"step:{i}, loss:{loss}\")\n",
    "\n",
    "    if i == 300:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset multi_nli (/home/ubuntu/.cache/huggingface/datasets/multi_nli/default/0.0.0/591f72eb6263d1ab527561777936b199b714cda156d35716881158a2bd144f39)\n",
      "100%|█████████████████████████████████████████████| 3/3 [00:00<00:00, 67.81it/s]\n",
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "torch.Size([256, 3])\n",
      "\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"../src/data_parallel.py\", line 59, in <module>\n",
      "    if i == 300:\n",
      "RuntimeError: Boolean value of Tensor with more than one value is ambiguous\n"
     ]
    }
   ],
   "source": [
    "!python ../src/data_parallel.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../images/dp_training.png)\n",
    "\n",
    "- 0번 GPU에 Output들이 모두 Gather 되기 때문에 사용량이 많은 것을 알 수 있음.\n",
    "- 만약 여러대의 GPU를 사용할 때, 특정 GPU의 용량이 많다면 `output_device`를 변경하여 출력을 원하는 곳으로 모을 수 있음.\n",
    "  - 예를 들어 0번 GPU가 8GB, 1번 GPU가 24GB라면 용량이 큰 1번 GPU에 모으는 것이 효율적.\n",
    "  - 이런 경우에 `output_device=1`와 같이 설정하여 1번 GPU로 출력을 모두 모을 수 있음.\n",
    "\n",
    "<br>\n",
    "\n",
    "## 2. `torch.nn.DataParallel`의 문제점\n",
    "\n",
    "\n",
    "### 1) 멀티쓰레드 모듈이기 때문에 Python에서 비 효율적.\n",
    "- Python은 GIL (Global Interpreter Lock)에 의해 하나의 프로세스에서 동시에 여러개의 쓰레드가 작동 할 수 없음.\n",
    "- 따라서 근본적으로 멀티 쓰레드가 아닌 **멀티 프로세스 프로그램**으로 만들어서 여러개의 프로세스를 동시에 실행하게 해야함.\n",
    "\n",
    "<br>\n",
    "\n",
    "### 2) 메모리 불균형이 일어나서 GPU를 100% 활용할 수 없음.\n",
    "- Output이 하나의 디바이스로 모이고, 한 디바이스가 모든 Loss를 계산하기 때문.\n",
    "- **Output을 하나의 디바이스로 모으지 않고 각 디바이스에서 자체적으로 Loss를 계산**하게 만들어야 함.\n",
    "- 따라서 아래와 같이 연산을 수정해야 함.\n",
    "\n",
    "### Parallel Loss Forward\n",
    "\n",
    "1. 입력된 mini-batch를 **Scatter**하여 각 디바이스로 전송.\n",
    "2. GPU-1에 올라와 있는 모델의 파라미터를 GPU-2,3,4로 **Broadcast**.\n",
    "3. 각 디바이스로 복제된 모델로 Forward하여 출력값을 구함.\n",
    "4. <s>구해진 출력값들을 **Gather**하여 GPU-1에 모음.</s> → **각 디바이스에서 자체적으로 Loss를 계산함.**\n",
    "\n",
    "![](../images/parallel_dp_forward.png)\n",
    "위: 기존 Data Parallel / 아래: 변경된 Data Parallel\n",
    "\n",
    "<br>\n",
    "\n",
    "### Parallel Loss Backward\n",
    "\n",
    "1. <s>GPU-1에 모여있는 출력값과 라벨을 이용하여 GPU-1에서 모든 Loss를 계산.</s> → **각 디바이스에서 자체적으로 Gradient를 계산함.**\n",
    "2. <s>계산된 각각의 Loss를 각 디바이스에 **Scatter**함.</s> → 생략\n",
    "3. 각 디바이스에서 Backward를 수행.\n",
    "4. 계산된 모든 Gradient를 GPU-1로 **Reduce**하여 GPU-1의 모델을 업데이트.\n",
    "\n",
    "![](../images/parallel_dp_backward.png)\n",
    "\n",
    "위: 기존 Data Parallel / 아래: 변경된 Data Parallel\n",
    "\n",
    "<br>\n",
    "\n",
    "### 3) 하나의 모델에서 업데이트 된 모델이 다른 device로 매 스텝마다 복제되어야 함.\n",
    "- Gradient를 Reduce하지 않고 평균을 계산해서 모든 device로 전송할 수 있다면 해결될 문제 → All-Reduce\n",
    "- Gradient의 평균\n",
    "\n",
    "<br>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kevin_env",
   "language": "python",
   "name": "kevin_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
